# Text-to-Image Generation using Stable Diffusion

## Project Overview

This project demonstrates text-to-image generation using the **Stable Diffusion** model, which is a state-of-the-art model in the field of AI for generating high-quality images from textual prompts. By leveraging the power of pre-trained generative models, this project allows you to input a text description, and it will generate a corresponding image based on that description.

The project utilizes the **diffusers** library, which integrates with popular AI models like Stable Diffusion, providing a seamless way to generate and visualize images using deep learning.

## Project Features
- **Text-to-Image Generation**: Converts text descriptions into vivid and creative images using the Stable Diffusion model.
- **Pre-trained Model**: Uses the pre-trained Stable Diffusion v1.4 model for image generation.
- **Python and Libraries**: Built in Python with dependencies such as `diffusers`, `transformers`, `accelerate`, and `matplotlib`.
- **Customizable**: The user can input any text prompt to generate unique images.

## Requirements

To run this project, you'll need to install the following Python dependencies:

- `diffusers`: The library to interact with the Stable Diffusion model.
- `transformers`: Provides tools for working with transformer models like Stable Diffusion.
- `accelerate`: Used for optimizing model performance.
- `matplotlib`: A library to display the generated image.

### Installation

Before running the project, you need to install the required dependencies. You can easily install them using `pip` by running the following command:

```bash
pip install -r requirements.txt
